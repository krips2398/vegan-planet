--- 
title: "Plant-Based Dining Trends"
author: "Sai Krupa Jangala, Kailande Cassamajor"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---
```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```

# Introduction


<!--chapter:end:index.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Data sources

For this analysis, we worked on two major datasets. One is the vegetarian restaurant data and the other is the survey data.

## Vegetarian and vegan restaurants data

We sourced this data from the [data.world](https://data.world/) website. The dataset used for this project is available [here](https://data.world/datafiniti/vegetarian-vegan-restaurants). This dataset contains of around 18000 restaurants that serve vegetarian or vegan food in the US.
Some of the columns used in this project are listed as follows:

- id - id column represents the id of each restaurant.
- address - address of every restaurant
- categories - categories of food items served at each restaurant for example : Seafood, Fish & Seafood Retail
- city - e.g., San Diego - city where the restaurant is located.
- claimed - the websites from which you can order the food.
- country - US for all the restaurants.
- dateAdded - date when the restaurant was opened.
- descriptions - a short description about reviews.
- latitude - latitude of the restaurant.
- longitude - longitude of the restaurant.
- name - name of the restaurant.
- province - abbreviated forms of the states in the United States. For example: California is represented as **CA**.

There are other columns as well but we will be using the columns described above extensively throughout our analysis. The detailed list and description of all the columns in the dataset can be found [here](https://developer.datafiniti.co/docs/business-data-schema).


A sample of the raw data is attached below:
```{r}
library(tidyverse)
library(kableExtra)
df <- read_csv('project_data/vegetarian_restaurants_US_datafiniti.csv')
df <- subset(df, select = -c(menus))
head(df,10) %>% kable(escape = FALSE) %>%
  kable_styling("striped", font_size = 9, full_width = FALSE) %>%
  scroll_box(width = "800px", height ="400px")
```

The number of unique values in each column of the data are listed as follows:
```{r, message=FALSE,warning=FALSE}
library(collapse)
df <- read_csv("data/vegetarian_restaurants_US_datafiniti.csv")
fNdistinct(df)
```

## Survey Data

This data source was available at the [faunalytics](https://faunalytics.org/) website. A survey was conducted for almost 1500 people who have transitioned or begining to transition into a vegetarian/vegan. The dataset can be found [here](https://faunalytics.org/wp-content/uploads/2017/04/Faunalytics-Current-Former-Veg-Study-Dataset-4-Groups.sav) There a total of 1023 columns in this dataset. The survey was conducted for almost 1387 participants. People from different age groups were invited to take the survey. This survey also contains respondents from different states and cities in the United States. A survey instrument has also been provided to understand the questions in the survey and the respondents answers. The survey instrument can be found [here](https://faunalytics.org/wp-content/uploads/2016/01/Faunalytics-Current-Former-Veg-Study-Survey-Instrument.pdf). The data was made available in the .sav format. We have used the pyreadstat module in python to read the data.
It also contains information about the following: 

- reasons behind the adoption of veganism 
- inconvienience that people are facing while transitioning or after the transition 
- age of every individual in the survey 
- health and taste concerns .
- demographic information including religion, race etc

The data was stored in such a way that each idea was split into 5 different columns. For example, if one has to analyse the reasons behind the motivation of veganisim, we will be having 7 different columns for the same. For example, ANIMALPROTECTION, HEALTH, COST etc. Each column will tell us how much people agree or disagree to a particular reason. Based on the user's opinions, the responses where categorized as follows:

- 1 - Strongly disagree
- 2 - Disagree
- 3 - Neither Agree nor Disagree
- 4 - Agree
- 5 - Strongly Agree

Here is a snapshot of the columns that contain opinion data.

```{r}
df <- read_csv("project_data/Data_sources.csv")
df %>% kable(escape = FALSE) %>%
  kable_styling("striped", font_size = 9, full_width = FALSE) %>%
  scroll_box(width = "800px", height ="400px")
```

The same pattern was used to capture Concerns, Reasons behind the motivation, Inconvienience reasons etc.
The length and transitions variables are recorded as follows:

- 1 - "Up to 3 months"
- 2 - "4–11 months"
- 3 - "1–2 years"
- 4 - "3–5 years" 
- 5 - "6–10 years"
- 6 - "More than 10 years"
- 7 - "Don’t know"

Here is a snapshot of some categorical columns present in the data:

```{r}
df <- read_csv("project_data/Data_source_2.csv")
df %>% kable(escape = FALSE) %>%
  kable_styling("striped", font_size = 9, full_width = FALSE) %>%
  scroll_box(width = "400px", height ="400px")
```


The [SPSS syntax file](https://faunalytics.org/wp-content/uploads/2016/01/Faunalytics-Current-Former-Veg-Study-Syntax-4-Groups.sps) provides a detailed list of all the columns and a short description about each column. This file was used to understand each column in the dataframe.



<!--chapter:end:02-data.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Data transformation


The code can be found at 

## Geospatial data

We would like to visualize the spread of vegetarian restaurants across different states in the United States. So we extracted the coloumns called PROVINCE. We then used US state mapper to map the state names to its abbreviations which is in the data. We created a new data frame which contains only two columns - Province and the number of restaurants in each province. The columns have been renamed to region and value to be compatible to the library that we are going to use. 

## Interactive component data.
We have a total of 7 columns in the dataset which will say 1 if a person was motivated to adopt veganism for that particular else it would be 0. The same repeats for all other reasons. The reasons are as follows

- Animal Protection
- Environment
- Cost
- Health
- Religious and Spiritual
- Social Influence
- Social Justice and World Hunger
- Food Trends
- Feeling of Disgust

We derieved 5 columns for each of the above reasons. Value 1 says that the user strongly disagree. 2 indicates disagree. 3 suggests neither agree nor disagree. 4 suggests that the user agree. 5 means that they strongly agree.

The counts for each reason and each column is taken into consideration.

## Cleaning of the categorical data.

All the categorical data that we have is present in the form of opinions. So, we counted the occurence of each opinion based on different categorical variables. For example,  we count the number of users who agree with a particular reason that has caused inconvineince. We have been a scale of 1-5 to decide how much a person agrees and disagrees to a particular reason. But, we reduced the scale to 1-3. 1 suggest that the person disagrees to a particular reason. 3 suggests that a person agrees to a particular reason of inconvienience. 2 indicates that a person neither agrees nor disagrees to a particular reason. The counts for each inconvineince reason has been generated. Similar kind of mechanism is applied to Transition, Duration variables which represents the amount of time that one required to transition into a vegan and for how long they have been following a vegan diet.  







<!--chapter:end:03-cleaning.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Missing values

```{r}
library(dplyr)
library(naniar)
library(mi)
library(ggplot2)
library(forcats)
library(ggmap)
library(tidyverse)
library(patchwork)
library(janitor)
library(tibble)
```

```{r fig.width=7, fig.height=5}
#df <- read.csv("/Users/saikrupa/Desktop/projects_in_R/data/vegetarian_restaurants_US_datafiniti.csv")
# "/Users/saikrupa/Desktop/projects_in_R/data/Datafiniti_Vegetarian_and_Vegan_Restaurants.csv"
df <- read.csv('project_data/Datafiniti_Vegetarian_and_Vegan_Restaurants.csv')
dat <- df %>% mutate_all(na_if,"")
vis_miss(dat, sort_miss = TRUE, warn_large_data = FALSE) +
  labs(title = "") +
  xlab("")
```
Observations:

- 38.3% of all observations in the data are missing while 61.7% of the observations in the data are present.
```{r}
colSums(is.na(dat)) %>% sort(decreasing = TRUE)
```

```{r}
x <- missing_data.frame(dat)
image(x = x)
#summary(x@patterns)
```
Observations:

- All of the missing observations observed are from 12 main variables as presented from the map above. 

```{r}
#summary(x@patterns)
```

#### Missing by borough
```{r}
df_b <- dat %>% 
  mutate(Borough = city)
percent_missing <- df_b %>% 
  group_by(Borough) %>% 
  summarize(num_restaurants = n(), num_na_claimed = sum(is.na(`claimed`))) %>% 
  mutate(percent_na = round(num_na_claimed/num_restaurants, 2)) %>% 
  arrange(-percent_na)
```
```{r}
df_b <- dat %>% 
  mutate(Borough = city)
percent_missing <- df_b %>% 
  group_by(Borough) %>% 
  summarize(num_restaurants = n(), num_na_menus_currency = sum(is.na(`menus.currency`))) %>%
  mutate(percent_na = round(num_na_menus_currency/num_restaurants, 2)) %>% arrange(-percent_na)
```

#### Number missing by city

```{r}
missing_counts <- dat %>% group_by(city) %>% summarise_all(~sum(is.na(.))) %>% transmute(city, sumNA = rowSums(.[-1]))
```

```{r fig.width=15, fig.height=20}
ggplot(data=missing_counts, aes(x=fct_reorder(city,-sumNA), y=sumNA)) + 
  geom_bar(stat="identity", color="blue", fill="lightblue") + 
  xlab("City") +
  ylab("Missing count") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 25), axis.text.y = element_text(vjust = 0.5, hjust=1, size = 25), axis.title.y =element_text(size = 25), axis.title.x =      element_text(size = 25))
```
Observations:

- We examined missing data by city, and interestingly enough, the majority of the missing data counts are those from New York City. 

- Observations from Brooklyn have the second highest number of missing data. 

#### Function for examining missing data 

```{r fig.size=20}
data.missing <- function(df, percent = 'FALSE'){
  
  missing_patterns <- data.frame(is.na(df)) %>%
  group_by_all() %>%
  count(name = "count", sort = TRUE) %>%
  ungroup()
  if(percent){
  missing_patterns$count = missing_patterns$count*100/nrow(df)
  }
  # Creating New missing patterns dataframe using the old one, this turns the TRUE/FALSE missing data into 1's and 0s. The adorn_totals("col") makes it so that a toal column for the sum of missing patterns in each row is appended to the entire dataframe. 

missing_patterns_new<- missing_patterns %>% mutate_all((as.integer)) %>% adorn_totals("col")

# Creates the pattern identiication. Appends a column called pattern_id that assigns a 0, 0,5, or 1 given the total number missing patterns - the count of missing patterns for each row. This will help in the colors of the overall map
missing_patterns_new <- missing_patterns_new %>%
  mutate(pattern_id=ifelse(missing_patterns_new$Total-missing_patterns_new$count==0,1,0.5))

#Creates a first identification column for each number of rows. there are 9 rows
# This is the final dataframe needed for the entire map
missing_patterns_new <- missing_patterns_new %>% rownames_to_column("id1")
missing_patterns_new$id1 <- as.factor(as.integer(missing_patterns_new$id1))

if(percent){
  missing_patterns$count = missing_patterns$count*100/nrow(df)
  p1 <- ggplot(data=missing_patterns_new,aes(x=fct_rev(reorder(id,1-count)),y=count)) + 
              geom_bar(aes(alpha=factor(missing_patterns_new$pattern_id)),stat = 'identity',fill = "#03b1fc") + 
              
              xlab("") + ylab("% rows") +
              ylim(0,100) + 
              scale_alpha_manual(values = c("0.5"=0.5,"1.0"=1), guide="none") +
              theme(axis.title.y=element_blank(), legend.position = "none") + 
              coord_flip() +
     theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 20), axis.text.y = element_text(vjust = 0.5, hjust=1, size = 20), axis.title.y
          =element_text(size = 20), axis.title.x =      element_text(size = 20))
}
else
{
p1 <- ggplot(data=missing_patterns_new,aes(x=fct_rev(reorder(id1,-count)),y=count)) + 
              geom_bar(aes(alpha=factor(missing_patterns_new$pattern_id)),stat = 'identity',fill = "#03b1fc") + 
              xlab("") + ylab("row count") +
              scale_alpha_manual(values = c("0.5"=0.5,"1.0"=1), guide="none") +
              theme(axis.title.y=element_blank(), legend.position = "none") + 
              coord_flip() + 
   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 20), axis.text.y = element_text(vjust = 0.5, hjust=1, size = 20), axis.title.y
          =element_text(size = 20), axis.title.x =      element_text(size = 20))
}
    

complete_case_id <- missing_patterns_new %>% 
  filter(pattern_id == 1) %>% 
  select(id1) %>% 
  as.character()

missing_col <- df %>% select(everything()) %>%
  summarise_all(funs(sum(is.na(.))))


miss_col <- data.frame(col=names(missing_col))

f <- c(missing_col[1,])

miss_col$count <- as.integer(unlist(f))

miss_col <- miss_col[order(-miss_col$count),]

rownames(miss_col) <- 1:nrow(miss_col)

miss_col <- miss_col %>% mutate(col = fct_reorder(col, desc(count)))

if(percent){
  miss_col$count = miss_col$count*100/nrow(df)
  p2 <- ggplot(data= miss_col, aes(x=col,y=count)) + 
  geom_bar(stat = 'identity', fill = "#03b1fc", alpha=0.5) +
  scale_x_discrete(label=function(x) abbreviate(x, minlength = 3)) +
  xlab("") +
  ylim(0,100) + 
  ylab("% rows missing") +
     theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 20), axis.text.y = element_text(vjust = 0.5, hjust=1, size = 20), axis.title.y
          =element_text(size = 20), axis.title.x =      element_text(size = 20))
}
else{
p2 <- ggplot(data= miss_col, aes(x=col,y=count)) + 
  geom_bar(stat = 'identity', fill = "#03b1fc", alpha=0.5) +
  scale_x_discrete(label=function(x) abbreviate(x, minlength = 3)) +
  xlab("") +
  ylab("num rows missing") + 
   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 20), axis.text.y = element_text(vjust = 0.5, hjust=1, size = 20), axis.title.y
          =element_text(size = 20), axis.title.x =      element_text(size = 20))
}

missing_map <- data.frame(is.na(df)) %>% 
  group_by_all() %>%
  count(name = "count", sort = TRUE) %>%
  ungroup()

missing_map <- subset(missing_map, select = -c(count))

tidycars <- missing_map %>% 
  rownames_to_column("id1") %>% 
  gather(key, value, -id1) %>% #gather key and value except id
  mutate(missing = ifelse(value==1, "yes", "no"))

tidycars <- tidycars %>% mutate(miss2=ifelse(missing=="yes",1,0))

tidycars$miss3 <- as.factor(ifelse(tidycars$id1 == complete_case_id,0.5,tidycars$miss2))

tidycars$key <- factor(tidycars$key, levels = levels(miss_col$col))
tidycars$id1 <- factor(tidycars$id1, levels = levels(missing_patterns_new$id))

if(complete_case_id == 0) {
g <- ggplot(tidycars, aes(x = key, y = fct_rev(id1), fill = miss3)) +
      geom_tile(color = "white") +
      #scale_fill_brewer(palette = "Blues") +
      scale_fill_manual(values=c("#cacaca","#b2a0e1","darkgray")) +
      scale_x_discrete(label=function(x) abbreviate(x, minlength = 3)) +
      xlab("variable") +
      ylab("missing data pattern") +
      #theme(legend.position = "none") + 
  theme(legend.position = "none", axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 20), axis.text.y = element_text(vjust = 0.5, hjust=1, size = 20), axis.title.y=element_text(size = 20), axis.title.x =      element_text(size = 20)) +
   annotate("text", x=length(unique(tidycars$key))/2, y=complete_case_id, label="complete cases")
}

else{
  g <- ggplot(tidycars, aes(x = key, y = fct_rev(id1), fill = miss3)) +
      geom_tile(color = "white") +
      #scale_fill_brewer(palette = "Blues") +
      scale_fill_manual(values=c("#cacaca","#b2a0e1","darkgray")) +
      scale_x_discrete(label=function(x) abbreviate(x, minlength = 3)) +
      xlab("variable") +
      ylab("missing data pattern") +
      #theme(legend.position = "none") + 
  theme(legend.position = "none", axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 20), axis.text.y = element_text(vjust = 0.5, hjust=1, size = 20), axis.title.y=element_text(size = 20), axis.title.x =      element_text(size = 20))
  
}

p2 + plot_spacer() + g + p1 + plot_layout(widths = c(4,1), heights = c(1,3))

}
```

#### Applying data.missing function to data

```{r fig.width=20, fig.height=15}

data.missing(df, percent = FALSE)

```

```{r fig.width=20, fig.height=15}

data.missing(df, percent = TRUE)

```
Observations:

- Based on the resulting maps of missing data, we can note there may be a possibility of there being correlations between the first 9 variables listed on the map, as these variables all seem to have missing data within the same rows. 

- 100% of the data within these rows also appear to be missing.

- The first missing data pattern displayed on the map accounts for just over 60% of the rows in the data

- The second missing data pattern displayed on the map accounts for just over 35% of the rows of the data

- There are no complete cases of no missing data within this dataset.



<!--chapter:end:04-missing.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Results
```{r}
library(dplyr)
library(ggplot2)
library(forcats)
library(ggmap)
library(tidyverse)
library(choroplethr)
library(vcd)
```

## Inconvience because of veganism
```{r fig.height=10,fig.width=15}
df <- read_csv('project_data/inconvience_reasons.csv')
tidydf <- df %>%
     gather(key = "opinion", value = "Counts", "Disagree", "Agree", "Neither agree nor disagree")
ggplot(
      tidydf,
      aes(Counts, 
          fct_reorder2(reason, opinion=="Disagree", Counts, .desc = FALSE),
          color = opinion)) +
      geom_point(aes(size=1)) + 
      ggtitle("Inconvience because of veganism") +
      ylab("") +
      theme_grey(16) +
      theme(plot.title = element_text(hjust = 0.5)) +
      guides(size=FALSE) 

options(repr.P.width=4,repr.P.height=10)
```

## Number of restuarants in each region
```{r fig.height=10, fig.width=10}
df_state <- read.csv("project_data/states_grouped_1.csv")
state_choropleth(df_state, title = "Number of Vegetarian restaurants in every state", legend="Counts") + scale_fill_brewer(palette=2)
```


## How many vegetarian restuarants are opened from 2014-2018

```{r}
df <- read_csv('project_data/timeseries_opening_of_restuarants.csv')
df <- df[order(df$date),]
df$tmp <- "-01"
df$date <- paste0(df$date,df$tmp)
df$date <- as.Date(df$date, format="%Y-%m-%d")
df = df[-1,]
ggplot(df, aes(date, counts, group = 1)) +
         geom_point(color="black") + 
         geom_line(colour="black") +
         geom_smooth(method ="loess",span = .3,se=FALSE, color="darkgreen") +
         scale_x_date(date_breaks = "3 month", date_labels = "%b %y") +
         labs(x = "Date", y = "Number of Vegetarain restaurants", title = "Number of Vegetarian restaurants opened over time")
```

## Length vs. Transition
```{r fig.height=10, fig.width=10}
df <- read_csv("project_data/age_transition_legth.csv")
#df$ALLTRANSITION <- as.integer(df$ALLTRANSITION)
#df$ALLLENGTH <- as.integer(df$ALLLENGTH)

mosaic(Time_for_transition ~ Length_of_veganism, labeling = vcd::labeling_border(rot_labels = c(0, 0)), df, direction=c("v","h"),main='Mosaic plot for Length and Transition to veganism')
```

## Bar plot
```{r}
df <- read_csv("project_data/age_difficulty_during_transition.csv")
df <- df[c("Age","difficulty_during_transition")]
df$difficulty_during_transition <- as.factor(df$difficulty_during_transition)
ggplot(df, aes(fct_infreq(difficulty_during_transition))) +
  geom_bar(color="darkgreen",fill = "palegreen3") + 
  ggtitle("What age group is facing a lot of difficulty during transition") +
  xlab("Opinion")+
  ylab("Count")+
  facet_wrap('Age') +
  theme_grey(14) + 
  theme(text = element_text(size=9), legend.position = "none", plot.title = element_text(hjust = 0.5))
```

```{r}
df_inc <- read_csv("project_data/age_difficulty_during_transition.csv")
df_inc
df_inc_1 <- read_csv('project_data/inconvience_reasons.csv')
```

```{r}
df_trans <- read_csv("project_data/age_transition_legth.csv")
df_trans
```

```{r}
sapply(df_trans, class)
```


```{r}
df_trans$ALLTRANSITION <- as.factor(df_trans$ALLTRANSITION)
```
```{r}
df_trans$ALLTRANSITION <- as.factor(df_trans$ALLTRANSITION)
ggplot(df_trans, aes(x=ALLAGEADOPTION, y=ALLTRANSITION)) + geom_boxplot() + theme_grey(16) + ggtitle(" Summary of loan amounts for each level of loan purpose") + xlab("Age")  + ylab("How Long before Fully Transitioned After Deciding") + theme(text = element_text(size=9), legend.position = "none")
```

```{r}
df_trans$ALLLENGTH <- as.factor(df_trans$ALLLENGTH)
ggplot(df_trans, aes(x=ALLAGEADOPTION, y=ALLLENGTH)) + geom_boxplot() + theme_grey(16) + ggtitle(" Summary of loan amounts for each level of loan purpose") + xlab("Age")  + ylab("Length of Diet") + theme(text = element_text(size=9), legend.position = "none")
```

```{r}
df_veg_reasons <- read_csv("project_data/reasons_for_veganism.csv")
df_veg_reasons
```

```{r}
df_veg_merged <- merge(df_trans, df_veg_reasons, by = "id")
df_veg_merged
```

```{r}
chosen_cols <- c("ALLTRANSITION","ALLLENGTH", "ALLANIMALPROTECTION",
                 "ALLENVIRONMENT", "ALLCOST","ALLHEALTH",
                 "ALLRELIGIOUSSPIRITUAL", "ALLSOCIALINFLUENCE",
                 "ALLSOCIALJUSTICEWORLDHUNGER", "ALLFOODTREND",
                 "ALLDISGUST")
df_veg_merged[chosen_cols] <- lapply(df_veg_merged[chosen_cols], factor)
                 
#df_pivoted <- df_veg_merged %>%
  #pivot_longer(everything(), manes_to = "")
ggplot(df_veg_merged, aes(x=ALLTRANSITION)) +
  geom_bar(color="darkgreen",fill = "palegreen3") + 
  ggtitle("Length to Transition vs. Length of Overall Diet") +
  xlab("How Long Partitipants took to Transition")+
  ylab("Count")+
  facet_wrap('ALLLENGTH') +
  theme_grey(14) + 
  theme(text = element_text(size=9), legend.position = "none", plot.title = element_text(hjust = 0.5))
```


```{r}
df_incondichot <- read_csv('project_data/inconvenience_dichot.csv')
df_incondichot


df_incondichot$ALLINCONVENIENCE4D <- as.factor(df_incondichot$ALLINCONVENIENCE4D)
df_incondichot$ALLLENGTH <- as.integer(df_incondichot$ALLLENGTH)
mosaic(ALLLENGTH~ALLINCONVENIENCE4D, df_incondichot, direction=c("v","h"),main='Length of Diet & Difficulty Accessing Health Foods')
```

```{r}
df_incondichot$ALLINCONVENIENCE3D <- as.factor(df_incondichot$ALLINCONVENIENCE3D)
mosaic(ALLLENGTH~ALLINCONVENIENCE3D, df_incondichot, direction=c("v","h"),main='Length of Diet & Trouble Finding Restaurants')
```

<!--chapter:end:05-results.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Interactive component


<!--chapter:end:06-interactive.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
```
# Conclusion


<!--chapter:end:07-conclusion.Rmd-->

